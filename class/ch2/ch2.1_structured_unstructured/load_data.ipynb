{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reading and Writing Structured/Unstructured Data in Python\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Structured Data\n",
        "\n",
        "Structured data refers to data that is organized in a predefined format, usually in the form of rows and columns.\n",
        "\n",
        "It follows a fixed schema, meaning the structure of the data is defined before data is stored.\n",
        "\n",
        "Because of this well-defined organization, structured data is easy to store, search, query, and analyze using traditional databases and data processing tools. \n",
        "\n",
        "Common examples include data stored in relational databases, spreadsheets, and CSV files, such as student records, transaction logs, and inventory tables.\n",
        "\n",
        "---\n",
        "\n",
        "## Unstructured Data\n",
        "\n",
        "Unstructured data refers to data that does not have a predefined format or fixed schema. \n",
        "\n",
        "It is not organized in a tabular form and cannot be easily stored or queried using traditional database systems.\n",
        "\n",
        "This type of data often contains text, images, audio, or video and requires preprocessing or advanced techniques such as text mining, natural language processing, or machine learning for analysis. \n",
        "\n",
        "Examples of unstructured data include emails, social media posts, documents, images, and multimedia files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. CSV (Comma-Separated Values) - Structured Data\n",
        "\n",
        "CSV is a common format for tabular data. It's structured with rows and columns separated by commas (or other delimiters).\n",
        "\n",
        "Because of its simple and lightweight structure, CSV is widely supported by databases, spreadsheet applications, and programming languages. \n",
        "\n",
        "\n",
        "### Reading CSV\n",
        "- Using pandas `pd.read_csv()` to load CSV into a DataFrame.\n",
        "- Options: delimiter, header, index_col, dtype, etc.\n",
        "- or Using csv module\n",
        "\n",
        "### Writing CSV\n",
        "- Use `df.to_csv()` to save a DataFrame to CSV.\n",
        "- Options: index, header, sep, mode, etc.\n",
        "- or Using csv module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV file written to: example.csv\n"
          ]
        }
      ],
      "source": [
        "# Example data for demonstration\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'Age': [25, 30, 35],\n",
        "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "# Writing to CSV using pandas\n",
        "csv_file = 'example.csv'\n",
        "df.to_csv(csv_file, index=False)\n",
        "print(f'CSV file written to: {csv_file}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Read CSV Data:\n",
            "      Name  Age         City\n",
            "0    Alice   25     New York\n",
            "1      Bob   30  Los Angeles\n",
            "2  Charlie   35      Chicago\n",
            "\n",
            "Read with options:\n",
            "          Age         City\n",
            "Name                      \n",
            "Alice    25.0     New York\n",
            "Bob      30.0  Los Angeles\n",
            "Charlie  35.0      Chicago\n"
          ]
        }
      ],
      "source": [
        "# Reading from CSV using pandas\n",
        "df_read = pd.read_csv(csv_file)\n",
        "print('Read CSV Data:')\n",
        "print(df_read)\n",
        "\n",
        "# Detailed options example\n",
        "df_read_with_options = pd.read_csv(csv_file, dtype={'Age': 'float'}, index_col='Name')\n",
        "print('\\nRead with options:')\n",
        "print(df_read_with_options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV file written using csv module to: example_module.csv\n",
            "['Name', 'Age', 'City']\n",
            "['Alice', '25', 'New York']\n",
            "['Bob', '30', 'Los Angeles']\n",
            "['Charlie', '35', 'Chicago']\n"
          ]
        }
      ],
      "source": [
        "# using csv module\n",
        "\n",
        "import csv\n",
        "# Writing to CSV using csv module\n",
        "csv_file_module = 'example_module.csv'\n",
        "with open(csv_file_module, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(data.keys())\n",
        "    writer.writerows(zip(*data.values()))\n",
        "print(f'CSV file written using csv module to: {csv_file_module}')\n",
        "\n",
        "# Reading from CSV using csv module\n",
        "with open(csv_file_module, mode='r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "        print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. JSON (JavaScript Object Notation) - Structured/Semi-Structured Data\n",
        "\n",
        "JSON is a lightweight format for structured data, often used in APIs and configurations.\n",
        "\n",
        "It represents data in keyâ€“value pairs and supports nested structures such as objects and arrays, making it flexible and easy to read by both humans and machines.\n",
        "\n",
        "### Reading JSON\n",
        "- Use `json.load()` for files or `json.loads()` for strings.\n",
        "- pandas `pd.read_json()` for DataFrame conversion.\n",
        "\n",
        "### Writing JSON\n",
        "- Use `json.dump()` or `json.dumps()`.\n",
        "- pandas `df.to_json()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JSON file written to: example.json\n"
          ]
        }
      ],
      "source": [
        "# Writing to JSON using pandas\n",
        "json_file = 'example.json'\n",
        "df.to_json(json_file, orient='records', indent=4)\n",
        "print(f'JSON file written to: {json_file}')\n",
        "\n",
        "# Using built-in json\n",
        "with open('example_builtin.json', 'w') as f:\n",
        "    json.dump(data, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Read JSON Data (pandas):\n",
            "      Name  Age         City\n",
            "0    Alice   25     New York\n",
            "1      Bob   30  Los Angeles\n",
            "2  Charlie   35      Chicago\n",
            "\n",
            "Read JSON Data (built-in):\n",
            "[{'Name': 'Alice', 'Age': 25, 'City': 'New York'}, {'Name': 'Bob', 'Age': 30, 'City': 'Los Angeles'}, {'Name': 'Charlie', 'Age': 35, 'City': 'Chicago'}]\n"
          ]
        }
      ],
      "source": [
        "# Reading JSON with pandas\n",
        "df_json = pd.read_json(json_file, orient='records')\n",
        "print('Read JSON Data (pandas):')\n",
        "print(df_json)\n",
        "\n",
        "# Reading with built-in json\n",
        "with open(json_file, 'r') as f:\n",
        "    data_loaded = json.load(f)\n",
        "print('\\nRead JSON Data (built-in):')\n",
        "print(data_loaded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handling Nested JSON\n",
        "- Nested JSON is very common in APIs, logs, and web data, where values can be dictionaries inside dictionaries or lists.\n",
        "- Use `json_normalize` in pandas for flattening."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalized Nested JSON:\n",
            "    name  details.age details.city\n",
            "0  Alice           25     New York\n",
            "1    Bob           30  Los Angeles\n"
          ]
        }
      ],
      "source": [
        "nested_data = {\n",
        "    'employees': [\n",
        "        {'name': 'Alice', 'details': {'age': 25, 'city': 'New York'}},\n",
        "        {'name': 'Bob', 'details': {'age': 30, 'city': 'Los Angeles'}}\n",
        "    ]\n",
        "\n",
        "}\n",
        "with open('nested.json', 'w') as f:\n",
        "    json.dump(nested_data, f)\n",
        "\n",
        "df_nested = pd.json_normalize(nested_data['employees'])\n",
        "print('Normalized Nested JSON:')\n",
        "print(df_nested)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Excel (XLSX) - Structured Data\n",
        "\n",
        "Excel files (.xlsx) are one of the most common structured data formats used in data analysis, business reporting, and research.\n",
        "\n",
        "Excel files handle spreadsheets with multiple sheets.\n",
        "\n",
        "### Reading Excel\n",
        "- Use `pd.read_excel()`.\n",
        "- Options: sheet_name, header, usecols, etc.\n",
        "\n",
        "### Writing Excel\n",
        "- Use `df.to_excel()`.\n",
        "- For multiple sheets, use `ExcelWriter`.\n",
        "\n",
        "\n",
        "openpyxl library for Excel (optional, but recommended for writing Excel files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Excel file written to: example.xlsx\n"
          ]
        }
      ],
      "source": [
        "# Writing to Excel\n",
        "excel_file = 'example.xlsx'\n",
        "df.to_excel(excel_file, index=False, sheet_name='Sheet1')\n",
        "print(f'Excel file written to: {excel_file}')\n",
        "\n",
        "# Writing multiple sheets\n",
        "with pd.ExcelWriter('multi_sheet.xlsx') as writer:\n",
        "    df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
        "    df.to_excel(writer, sheet_name='Sheet2', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Read Excel Data:\n",
            "      Name  Age         City\n",
            "0    Alice   25     New York\n",
            "1      Bob   30  Los Angeles\n",
            "2  Charlie   35      Chicago\n",
            "\n",
            "Read specific columns:\n",
            "      Name  Age\n",
            "0    Alice   25\n",
            "1      Bob   30\n",
            "2  Charlie   35\n",
            "\n",
            "Sheets:\n",
            "Sheet1:\n",
            "      Name  Age         City\n",
            "0    Alice   25     New York\n",
            "1      Bob   30  Los Angeles\n",
            "2  Charlie   35      Chicago\n",
            "Sheet2:\n",
            "      Name  Age         City\n",
            "0    Alice   25     New York\n",
            "1      Bob   30  Los Angeles\n",
            "2  Charlie   35      Chicago\n"
          ]
        }
      ],
      "source": [
        "# Reading Excel\n",
        "df_excel = pd.read_excel(excel_file, sheet_name='Sheet1')\n",
        "print('Read Excel Data:')\n",
        "print(df_excel)\n",
        "\n",
        "# Reading specific columns\n",
        "df_cols = pd.read_excel(excel_file, usecols=['Name', 'Age'])\n",
        "print('\\nRead specific columns:')\n",
        "print(df_cols)\n",
        "\n",
        "# Reading multiple sheets\n",
        "dfs = pd.read_excel('multi_sheet.xlsx', sheet_name=None)\n",
        "print('\\nSheets:')\n",
        "for sheet, df_sheet in dfs.items():\n",
        "    print(f'{sheet}:\\n{df_sheet}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Text Files - Unstructured Data\n",
        "\n",
        "Text files are unstructured and can contain free-form text.\n",
        "\n",
        "They contain free-form text without a predefined schema, making them harder to analyze directly compared to structured formats like Excel or CSV.\n",
        "\n",
        "Examples: news articles, reviews, emails, logs, social media posts.\n",
        "\n",
        "Text files are considered unstructured because:\n",
        "\n",
        "- No fixed rows and columns\n",
        "- No data types or schema\n",
        "- Content may be sentences, paragraphs, logs, or notes\n",
        "- Meaning is embedded in natural language\n",
        "\n",
        "### Reading Text\n",
        "- Use `open()` with 'r' mode.\n",
        "- Methods: read(), readline(), readlines().\n",
        "\n",
        "### Writing Text\n",
        "- Use `open()` with 'w' or 'a' mode.\n",
        "- Methods: write(), writelines()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text file written to: example.txt\n"
          ]
        }
      ],
      "source": [
        "# Writing to text file\n",
        "text_file = 'example.txt'\n",
        "with open(text_file, 'w') as f:\n",
        "    f.write('This is line 1.\\n')\n",
        "    f.write('This is line 2.\\n')\n",
        "    f.writelines(['Line 3.\\n', 'Line 4.\\n'])\n",
        "print(f'Text file written to: {text_file}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entire content:\n",
            "This is line 1.\n",
            "This is line 2.\n",
            "Line 3.\n",
            "Line 4.\n",
            "\n",
            "\n",
            "Line by line:\n",
            "This is line 1.\n",
            "This is line 2.\n",
            "Line 3.\n",
            "Line 4.\n",
            "\n",
            "Lines list:\n",
            "['This is line 1.\\n', 'This is line 2.\\n', 'Line 3.\\n', 'Line 4.\\n']\n"
          ]
        }
      ],
      "source": [
        "# Reading entire text\n",
        "with open(text_file, 'r') as f:\n",
        "    content = f.read()\n",
        "print('Entire content:')\n",
        "print(content)\n",
        "\n",
        "# Reading line by line\n",
        "print('\\nLine by line:')\n",
        "with open(text_file, 'r') as f:\n",
        "    for line in f:\n",
        "        print(line.strip())\n",
        "\n",
        "# Reading all lines into list\n",
        "with open(text_file, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "print('\\nLines list:')\n",
        "print(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleanup\n",
        "Optionally, remove generated files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# files_to_remove = ['example.csv', 'example.json', 'example_builtin.json', 'nested.json', 'example.xlsx', 'multi_sheet.xlsx', 'example.txt']\n",
        "# for file in files_to_remove:\n",
        "#     if os.path.exists(file):\n",
        "#         os.remove(file)\n",
        "#         print(f'Removed: {file}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv (3.12.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
